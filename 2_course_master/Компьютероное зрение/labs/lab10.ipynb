{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p align='center'>Лабораторная работа №10</p>\n",
    "## <p align='center'>Deep Learning</p>\n",
    "\n",
    "<p align='right'>Выполнил: студент гр. 5.306М Лаптев А.В.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN\n",
    "Приведенный ниже пример кода показывает возможности работы с моделью GoogleNet.\n",
    "\n",
    "В данном примере используются методы blobFromImage() для предобрабоки изображения перед загрузкой в модель, а также метод для загрузки модели - readNetFromCaffe(), setInput() для загрузки входного тензора в модель, forward() для получения вывода модели, а также argsoft() для получения индексов в порядке их вероятностного распределения.\n",
    "\n",
    "Метод blobFromImage() может принимать следующие аргументы:\n",
    "* image: входное изображение с 1, 3 или 4 каналами;\n",
    "* scaleFactor: коэффициент увеличения/уменьшения изображения;\n",
    "* size: пространственный размер входного изображения;\n",
    "* mean: скаляр со средними значениями, которые вычитаются из каналов;\n",
    "* swapRB: флаг, указывающий на смену первого и последнего канала в 3-канальном изображении;\n",
    "* crop: флаг, указывающий на то будет ли обрезано изображение после изменения размера;\n",
    "* ddepyh: глубина выходного тензора.\n",
    "\n",
    "Метод readNetFromCaffe() принимает следующие 2 аргумента:\n",
    "* prototxt: путь к файлу с текстовым описанием сети;\n",
    "* caffeModel: путь к файлу с предобученной моделью.\n",
    "\n",
    "Метод setInput() может принимать аргументы:\n",
    "* blob: новый тензор (сформированный с помощью blobFromImage());\n",
    "* name: имя входного слоя;\n",
    "* scaleFactor: шкала нормализации (необязательный параметр);\n",
    "* mean: среднее значение вычитания (необязательный параметр).\n",
    "\n",
    "Для метода forward() предусмотрен только один аргумент, который представляет собой имя выхода в строковом виде.\n",
    "\n",
    "Метод argsort() может принимать следующие аргументы:\n",
    "* a: исходный массив;\n",
    "* axis: ось для сортировки;\n",
    "* kind: вид алгоритма сортировки;\n",
    "* order: указывает какие поля сравнивать в очередности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: drake\n",
      "  probability: 0.9999695\n",
      "class: red-breasted merganser, Mergus serrator\n",
      "  probability: 2.9070698e-05\n",
      "class: goose\n",
      "  probability: 7.0552625e-07\n",
      "class: American coot, marsh hen, mud hen, water hen, Fulica americana\n",
      "  probability: 6.5966043e-07\n",
      "class: albatross, mollymawk\n",
      "  probability: 4.7360803e-08\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "# read names of classes\n",
    "with open('../resources/synset_words.txt') as f:\n",
    "    classes = [x[x.find(' ') + 1:] for x in f]\n",
    "\n",
    "image = cv.imread('../resources/duck07.png')\n",
    "# create tensor with 224x224 spatial size and subtract mean values (104, 117, 123) \n",
    "# from corresponding channels (R, G, B)\n",
    "input = cv.dnn.blobFromImage(image, 1, (224, 224), (104, 117, 123))\n",
    "\n",
    "# load model from caffe\n",
    "net = cv.dnn.readNetFromCaffe(\n",
    "    '../resources/deploy.prototxt',\n",
    "    '../resources/bvlc_googlenet.caffemodel'\n",
    ")\n",
    "# feed input tensor to the model\n",
    "net.setInput(input)\n",
    "# perform inference and get output\n",
    "out = net.forward()\n",
    "# get indices with the highest probability\n",
    "indexes = np.argsort(out[0])[-5:]\n",
    "for i in reversed(indexes):\n",
    "    print('class:', classes[i], ' probability:', out[0][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В приведенном ниже примере не используется никаких новых методов, но реализован алгоритм для распознавания объектов с использованием DNN, а конкретнее -  модели MobileNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Загружается модель...\n",
      "[INFO] Обнаружение объектов...\n",
      "[INFO] bird: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Укажите пути к файлам вручную\n",
    "image_path = \"../resources/duck07.png\"  # Путь к изображению\n",
    "confidence_threshold = 0.2  # Минимальная уверенность для фильтрации слабых детекций\n",
    "\n",
    "# Классы, которые может распознавать MobileNet SSD\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "           \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "           \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "# Генерация случайных цветов для рамок\n",
    "COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))\n",
    "\n",
    "# Загрузка модели\n",
    "print(\"[INFO] Загружается модель...\")\n",
    "new_net = cv.dnn.readNetFromCaffe(\n",
    "    '../resources/mobilenet_deploy.prototxt',\n",
    "    '../resources/mobilenet_iter_73000.caffemodel'\n",
    ")\n",
    "\n",
    "# Загрузка изображения\n",
    "image = cv.imread(image_path)\n",
    "(h, w) = image.shape[:2]\n",
    "\n",
    "# Преобразование изображения в формат, подходящий для нейросети\n",
    "blob = cv.dnn.blobFromImage(\n",
    "    cv.resize(image, (300, 300)),\n",
    "    0.007843,\n",
    "    (300, 300),\n",
    "    127.5\n",
    ")\n",
    "\n",
    "# Обнаружение объектов\n",
    "print(\"[INFO] Обнаружение объектов...\")\n",
    "new_net.setInput(blob)\n",
    "detections = new_net.forward()\n",
    "\n",
    "# Обработка детекций\n",
    "for i in np.arange(0, detections.shape[2]):\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "    \n",
    "    if confidence > confidence_threshold:\n",
    "        idx = int(detections[0, 0, i, 1])\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "        label = \"{}: {:.2f}%\".format(CLASSES[idx], confidence * 100)\n",
    "        print(\"[INFO]\", label)\n",
    "        \n",
    "        cv.rectangle(\n",
    "            image,\n",
    "            (startX, startY),\n",
    "            (endX, endY),\n",
    "            COLORS[idx],\n",
    "            2\n",
    "        )\n",
    "        y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "        cv.putText(\n",
    "            image,\n",
    "            label,\n",
    "            (startX, y),\n",
    "            cv.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            COLORS[idx],\n",
    "            2\n",
    "        )\n",
    "\n",
    "# Отображение результата\n",
    "cv.imshow(\"Output\", image)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
