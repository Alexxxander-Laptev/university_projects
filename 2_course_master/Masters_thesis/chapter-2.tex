% Глава про разработку всех решателей

\chapter{Методология решения задач CAPTCHA}

\section{Общие подходы к автоматизированному решению CAPTCHA}

Для автоматизации решения CAPTCHA могут применяться различные методы и подходы, 
которые зависят от конкретной реализации CAPTCHA. В рамках данной работы можно 
выделить следующие методы:

\begin{enumerate}
    \item реализация CAPTCHA в аудиоформате:
    \begin{enumerate}
        \item шумоподавление и фильтрация;
        \item распознавание речи;
        \item преобразование речи в текст.
    \end{enumerate}
    \item реализация CAPTCHA в текстовом формате:
    \begin{enumerate}
        \item бинаризация изображения и фильтрация фона;
        \item сегментация символов;
        \item классификация символов;
        \item распознавание последовательности символов;
        \item аугментация данных;
        \item генерация синтетических датасетов.
    \end{enumerate}
    \item реализация CAPTCHA в графическом формате:
    \begin{enumerate}
        \item нормализация и ручная разметка изображений;
        \item детекция объектов;
        \item сегментация объектов;
        \item классификация фрагментов изображения;
        \item поиск и сопоставление с шаблоном. 
    \end{enumerate}
    \item общие подходы для большинства реализаций:
    \begin{enumerate}
        \item анализ структуры HTML-документа на стороне клиента;
        \item автоматизация кликов и действий на web-странице.
    \end{enumerate}
\end{enumerate}

Для каждого формата одним из основополагающих этапов является этап 
предобработки исходного файла. Для аудиозаписей, которые используются в Audio 
CAPTCHA требуется применить шумоподавление и фильтрацию.

Шумоподавление (шумопонижение) -- процесс устранения или уменьшения нежелательных 
шумов из аудиосигнала с целью повышения его качества или уменьшения уровня ошибок 
при передаче и хранении данных. Методы шумоподавления могут быть реализованы как 
аппаратно, так и программно, и направлены на увеличение отношения сигнал/шум.(https://fastercapital.com/ru/content/%D0%9A%D0%BE%D0%BC%D0%BF%D1%8C%D1%8E%D1%82%D0%B5%D1%80%D0%BD%D0%B0%D1%8F-%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B0-%D0%B7%D0%B2%D1%83%D0%BA%D0%B0--%D0%BA%D0%B0%D0%BA-%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%B0%D1%82%D1%8B%D0%B2%D0%B0%D1%82%D1%8C-%D0%B8-%D1%83%D0%BB%D1%83%D1%87%D1%88%D0%B0%D1%82%D1%8C-%D0%B7%D0%B2%D1%83%D0%BA-%D1%81-%D0%BF%D0%BE%D0%BC%D0%BE%D1%89%D1%8C%D1%8E-%D0%BA%D0%BE%D0%BC%D0%BF%D1%8C%D1%8E%D1%82%D0%B5%D1%80%D0%BE%D0%B2.html)

Фильтрация -- процесс удаления или ослабления определённых частотных составляющих 
аудиосигнала при сохранении других. Фильтрацию можно использовать для удаления 
шума, частотный спектр которого отличается от желаемого сигнала.

Фильтрация играет важную роль в улучшении качества звучания аудиофайлов, 
эффективном подавлении шумов и помех, а также в создании специальных звуковых 
эффектов.

Для CAPTCHA в текстовом формате в качестве предобработки используется бинаризация 
и фильтрация фоновых шумов для упрощения следующих этапов обработки.

Бинаризация -- процесс преобразования цветного или полутонового изображения в 
двухцветное (черно-белое), где каждый пиксель принимает одно из двух возможных 
значений: 0 (черный) или 1 (белый). Основным параметром бинаризации является 
пороговое значение, с которым сравнивается яркость каждого пикселя. Существуют 
различные методы бинаризации, включая глобальные и локальные подходы.(https://cyberleninka.ru/article/n/issledovanie-metodov-binarizatsii-izobrazheniy/viewer)

Бинаризация широко используется в задачах распознавания текста, где упрощение 
изображения до двух цветов облегчает выделение символов и их последующее 
распознавание.

Фильтрация фонового шума -- процесс удаления или уменьшения нежелательных шумов, 
которые могут мешать анализу или распознаванию содержимого изображения. Шумы 
могут возникать из-за различных факторов, таких как условия съёмки, качество 
оборудования или передача данных. В частности, для CAPTCHA фоновые шумы 
генерируются намеренно.

Существует большое количество методов фильтрации шума, включая:

\begin{enumerate}
    \item Гауссов фильтр: используется для размытия изображения с целью удаления 
    высокочастотного шума;
    \item медианный фильтр: заменяет значение каждого пикселя на медиану значений 
    в его окрестности, эффективно устраняя импульсные шумы;(МЕТОДИКА УСТРАНЕНИЯ ШУМА НА ОКТ-ИЗОБРАЖЕНИЯХ)
    \item частотная фильтрация: применяется в частотной области для удаления 
    определённых частотных компонентов, связанных с шумом.(https://www.xn----8sbempclcwd3bmt.xn--p1ai/article/16686)
\end{enumerate}

Эффективная фильтрация фонового шума особенно важна при обработке изображений с 
текстом, так как наличие шума может затруднить или сделать невозможным корректное 
распознавание символов.

Для облегчения работы модели в дальнейшем, для графических CAPTCHA в качестве 
предобработки используется нормализация и ручная разметка изображений датасета.

Нормализация -- процесс приведения изображений к единому стандарту по 
определённым характеристикам, таким как размер, яркость, контрастность или 
геометрические параметры. Целью нормализации является обеспечение однородности 
входных данных для последующей обработки или анализа.(Gonzalez, R. C., \& Woods, R. E. (2018). Digital Image Processing (4th Edition). Pearson)

Разметка изображений -- процесс аннотирования изображений с целью идентификации 
и классификации объектов или областей интереса на изображении. Разметка является 
ключевым этапом в подготовке данных для обучения моделей компьютерного зрения и 
машинного обучения.

Разметка изображений обеспечивает модели данными, необходимыми для обучения 
точному распознаванию и интерпретации визуальной информации. Размеченные 
фотографии используются в различных задачах, от обнаружения объектов до 
автоматической обработки изображений.($https://annotate.ru/blog/semanticheskaya_razmetka_dlya_mashinnogo_obucheniya$)

Дальнейшие подходы и методы связаны непосредственно с поиском решения задания 
CAPTCHA и также специфичны для каждой реализации CAPTCHA.

Распознавание речи -- технология преобразования устной речи в текстовую форму. 
Современные системы ASR (Automatic Speech Recognition) используют глубокие 
нейронные сети для обработки аудиосигналов и преобразования их в текст.(https://www.assemblyai.com/blog/what-is-asr)

Преобразование речи в текст -- процесс транскрибирования устной речи в письменную 
форму. Этот процесс включает в себя анализ аудиосигнала, выделение речевых 
признаков и преобразование их в текст.(https://h2o.ai/wiki/speech-to-text/)

Задача сегментации представляет из себя процесс разделения изображения на 
дискретные группы пикселей для обнаружения важных участков изображения или 
объектов. В задачах компьютерного зрения, таких как распознавание текста на 
изображениях, сегментация помогает выделить отдельные символы или слова для 
последующей обработки.(https://www.ibm.com/think/topics/image-segmentation)

Задача классификации представляет собой процесс присвоения входным данным одной 
из предопределённых категорий. В контексте обработки изображений, классификация 
может использоваться для определения наличия текста на изображении, для 
распознавания символов или различных объектов.(https://www.sciencedirect.com/topics/engineering/image-classification)

Распознавание последовательности символов -- это задача извлечения и 
интерпретации последовательности символов из входных данных, таких как 
изображение или аудиосигнал. В системах OCR (оптического распознавания символов) 
это включает в себя определение порядка символов и их преобразование в текст.($https://aws.amazon.com/what-is/ocr/?nc1=h_ls$)

Аугментация данных -- метод увеличения объёма обучающего набора данных путём 
применения различных трансформаций к существующим данным. В задачах обработки 
изображений это может включать повороты, масштабирование, изменение яркости и 
контрастности.(https://www.ibm.com/think/topics/data-augmentation)

Генерация синтетических датасетов -- процесс создания искусственных данных для 
обучения моделей машинного обучения. Это особенно полезно, когда реальные данные 
ограничены или трудно доступны.(https://www.nvidia.com/en-us/glossary/synthetic-data-generation/)

Детекция объектов -- задача определения и локализации объектов на изображении. В 
системах CAPTCHA это может использоваться для идентификации определённых 
элементов, таких как дорожные знаки или транспортные средства.(https://www.ibm.com/think/topics/object-detection)

Поиск и сопоставление с шаблоном -- метод обработки изображений, используемый 
для поиска частей входного изображения (большого изображения или целевого 
изображения), которые соответствуют шаблонному изображению (эталонному 
изображению или меньшему изображению). Сопоставление шаблонов обычно 
используется для задач обнаружения объектов, распознавания изображений и 
распознавания образов.(https://blog.roboflow.com/template-matching/)

Также, задача автоматизации решения CAPTCHA была бы нерешаема без 
непосредственного взаимодействия с браузером без участия пользователя, для чего 
применяются описанные ниже подходы.

Анализ структуры HTML-страницы -- процесс разбора и интерпретации HTML-кода 
web-страницы для извлечения информации или автоматизации взаимодействия с 
элементами страницы.(https://www.geeksforgeeks.org/html-parsing-and-processing/)

Автоматизация действий пользователя -- это использование программных средств для 
имитации действий пользователя, таких как клики мышью, ввод текста или навигация 
по интерфейсу. Это может применяться для автоматического прохождения CAPTCHA или 
тестирования пользовательских интерфейсов.(https://www.testresults.io/definitions/automated-user-interaction)

\section{Архитектуры нейросетей для различных форматов CAPTCHA}

В данной работе рассмотрены три наиболее популярные и частовстречающиеся 
реализации CAPTCHA, которые применяются для защиты web-ресурсов: аудио CAPTCHA, 
текстовые CAPTCHA и графические CAPTCHA (CAPTCHA с изображениями). Для каждой 
реализации необходим свой подход к решению, разный набор инструментов и библиотек.

Далее для каждой из реализаций будцт рассмотрены различные архитектуры нейронных 
сетей, которые могут быть использованы для автоматизации решения CAPTCHA.

\textbf{Архитектуры нейронных сетей для аудио CAPTCHA}

Для аудио CAPTCHA доступны следующие архитектуры нейронных сетей и инструменты:

\begin{enumerate}
    \item Открытые API для работы с языковыми моделями от Google, Microsoft и 
    других;
    \item Написать еще несколько вариантов...
\end{enumerate}

% TODO: Более подпробно рассмотреть каждый из вариантов с привлечением литературы и так далее

\textbf{Архитектуры нейронных сетей для текстовых CAPTCHA}

Для задачи решения текстовых CAPTCHA могут быть использованы различные модели 
нейронных сетей, которые поддерживают обработку последовательностей различной 
длины. Среди таких архитектур и инструментов можно выделить следующие:

\begin{enumerate}
    \item оптическое распознавание символов (Tesseract OCR);
    \item cверточные рекурентные нейронные сети с функцией потерь CTC (CRNN + 
    CTC);
    \item архитектура последовательного обучения (Sequence-to-Sequence).
\end{enumerate}

Tesseract OCR -- это свободный движок оптического распознавания текста, 
изначально разработанный в Hewlett-Packard в 1985–1995 годах и в дальнейшем 
выпущенный как open-source-проект Google в 2005 году. В настоящее время он 
поддерживается и активно развивается сообществом под эгидой Google. С версии 4.0 
Tesseract использует глубокую нейросетевую архитектуру, что значительно улучшило 
его производительность на задачах распознавания сложных текстов и документов.(An Overview of the Tesseract OCR Engine, Adrian Rosebrock. OCR with OpenCV, Tesseract, and Python. PyImageSearch.)

Основные этапы обработки текста в Tesseract:(Adrian Rosebrock. OCR with OpenCV, Tesseract, and Python. PyImageSearch.)

\begin{enumerate}
    \item предобработка изображения: включает бинаризацию, удаление шумов, 
    коррекцию наклона и выравнивание; эти шаги направлены на улучшение качества 
    входного изображения для более точного распознавания;
    \item разметка структуры документа: изображение разбивается на блоки, строки 
    и отдельные слова; сначала происходит анализ макета документа, включая 
    идентификацию текста, таблиц, изображений и других структур;
    \item распознавание текста: начиная с версии 4.0, Tesseract использует LSTM 
    (Long Short-Term Memory) -- разновидность рекуррентных нейросетей, 
    позволяющую учитывать контекст в последовательности символов; распознавание 
    не требует предварительной сегментации символов -- вместо этого используется 
    подход Connectionist Temporal Classification (CTC), обеспечивающий 
    сопоставление входной последовательности признаков с выходной строкой текста;
    \item постобработка: включает коррекцию ошибок с помощью встроенных языковых 
    моделей, фильтрацию недопустимых символов и оптимизацию финального вывода 
    текста.
\end{enumerate}

Нейросетевой движок в Tesseract 4.0 построен следующим образом:(An Overview of the Tesseract OCR Engine)

\begin{enumerate}
    \item входное изображение пропускается через сверточный слой (convolutional 
    layer) для извлечения признаков;
    \item далее признаки передаются в двунаправленные LSTM-ячейки (BiLSTM), 
    способные учитывать как предыдущий, так и последующий контексты;
    \item выход LSTM обрабатывается функцией CTC (Connectionist Temporal 
    Classification), которая выравнивает вероятности символов по времени и строит 
    финальную строку текста.
\end{enumerate}

Архитектура движка Tesseract на примере обработки входной последовательности 
приведена на рис.~\ref{fig:tesseract}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{
        imgs/theory/TesseractOCR.png
    }
    \caption{Архитектура нейросетевого движка Tesseract OCR.}
    \label{fig:tesseract}
\end{figure}
\vspace{-0.85cm}

Этот подход особенно устойчив к искажениям и перемещениям текста, поскольку 
модель обучается <<видеть>> всю строку целиком, а не по символам.

Преимущества Tesseract:(Adrian Rosebrock. OCR with OpenCV, Tesseract, and Python. PyImageSearch.)

\begin{enumerate}
    \item гибкость: поддержка множества языков, включая написание справа-налево, 
    китайский, японский и арабский;
    \item обучаемость: пользователь может дообучать модель на своих собственных 
    данных;
    \item интеграция: легко используется совместно с библиотеками обработки 
    изображений, такими как OpenCV.
\end{enumerate}

Архитектура CRNN (Convolutional Recurrent Neural Network) с CTC (Connectionist 
Temporal Classification) -- это специализированный подход к распознаванию 
последовательностей на входах переменной длины. Он широко применяется в OCR, 
распознавании речи и жестов, где отсутствует строгое выравнивание между входами 
и метками.(Ian Goodfellow, Yoshua Bengio, Aaron Courville. Deep Learning)

Данный подход объединяет сверточные нейронные сети (для извлечения признаков), 
рекуррентные нейронные сети (для моделирования зависимости во 
времени/пространстве) и CTC (для сопоставления выходной последовательности с 
целевым результатом без предварительной сегментации).

Первая составляющая архитектуры -- сверточная нейронная сеть (CNN), задача 
которой -- извлечь дискретные признаки из исходного изображения (например, строки 
текста, номера или CAPTCHA).

Архитектура сверточных нейронных сетей состоит из комбинации слоев:

\begin{enumerate}
    \item сверточные слои, извлекают локальные пространственные шаблоны 
    (например, края, формы);
    \item пулинговые слои, которые уменьшают размерность и повышают 
    инвариантность;
    \item выходной слой, который представляет собой матрицу 
    признаков, часто сжатую по вертикали, но сохраняющую пространственную структуру 
    по ширине, что формирует последовательность признаков, где каждый вектор 
    соответствует <<временной метке>> (например, потенциальному символу).
\end{enumerate}

После получения последовательности признаков из CNN, она поступает на вход 
рекуррентной нейронной сети для анализа временной структуры последовательности 
признаков. Наиболее часто используется двунаправленная LSTM, поскольку она 
обрабатывает последовательность слева направо и справа налево, позволяя учитывать 
как предшествующий, так и последующий контекст, что особенно важно при наличии 
похожих символов и искажений.(Ian Goodfellow, Yoshua Bengio, Aaron Courville. Deep Learning)

Результатом является последовательность выходных векторов, каждый из которых 
соответствует одному <<временному шагу>> -- потенциальному символу.

Выходы из рекуррентной части подаются на полносвязный слой (или линейную 
проекцию), где каждый вектор переводится в вектор вероятностей по алфавиту 
(включая специальный пустой символ, обозначающий отсутствие выхода).

Затем применяется CTC (Connectionist Temporal Classification) -- 
специализированная функция потерь, предназначенная для задач, где отсутствует 
выравнивание между входной и выходной последовательностью.(Connectionist Temporal Classification: Labelling Unsegmented
Sequence Data with Recurrent Neural Networks)

CTC обладает следующими особенностями:

\begin{enumerate}
    \item не требует сегментации или аннотированных позиций символов;
    \item поддерживает множество путей к одному выходу;
    \item вводит символ <<blank>> для обозначения промежутков или 
    неопределенности;
    \item обеспечивает обучение <<end-to-end>> на уровне целых строк текста.
\end{enumerate}

Архитектура Sequence-to-Sequence (Seq2Seq) представляет собой класс нейронных 
сетей, предназначенных для преобразования одной последовательности элементов в 
другую, при этом длины входной и выходной последовательностей могут различаться. 
Первоначально эта архитектура была предложена для задач машинного перевода 
(https://arxiv.org/abs/1409.3215), однако в последующем она нашла широкое применение и в 
других областях, таких как распознавание речи, автоматическая транслитерация, 
генерация текстов и, в частности, распознавание текстовых CAPTCHA.

Основу Seq2Seq составляет двухкомпонентная архитектура: энкодер и декодер. 
Энкодер последовательно обрабатывает входные данные (например, текст или объекты, 
извлечённые из изображения с помощью сверточной сети) и кодирует их в вектор 
фиксированной длины -- так называемый вектор контекста. Декодер, в свою очередь, 
получает этот вектор и генерирует выходную последовательность, по одному элементу 
за шаг, используя скрытое состояние и ранее сгенерированные элементы.

Классическая реализация Seq2Seq использует рекуррентные нейронные сети (RNN), 
включая их модификации -- LSTM и GRU. В энкодере последовательность входных 
векторов обрабатывается пошагово, и финальное скрытое состояние используется как 
компактное представление всей последовательности. Это состояние затем передаётся 
в декодер, который генерирует выход, начиная с начального маркера.

Одной из ключевых проблем базовой Seq2Seq-модели является невозможность 
эффективно работать с длинными входными последовательностями, поскольку 
информация вектора контекста может быть потеряна. Для преодоления этого 
ограничения была предложена модификация с использованием механизма внимания, 
позволяющего декодеру на каждом шаге фокусироваться на различных частях входной 
последовательности.(https://arxiv.org/abs/1508.04025).

\textbf{Архитектуры нейронных сетей для графических CAPTCHA}

При решении графических CAPTCHA важными являются возможности модели по детекции
и сегментации объектов, поскольку данные CAPTCHA могут требовать как обычного 
поиска объекта, так и выбора клеток, в которых содержится объект. Для решения 
данныхзадач могут применяться следующие инструменты и архитектуры нейронных сетей:

\begin{enumerate}
    \item YOLO;
    \item DETR;
    \item Faster R-CNN.
\end{enumerate}

% TODO: Добавить больше теоретической информации с привлечением литературы

\section{Подготовка и аннотация датасетов}

\textbf{Подготовка датасета для тектcовых CAPTCHA}

Поскольку в открытом доступе отсутствует достаточное количество данных для 
формирования сбалансированного датасета, было принято решение о генерации 
синтетических изображений с использованием специализированных библиотек. В 
качестве основного инструмента выбрана библиотека captcha на языке Python, 
обладающая необходимым функционалом для создания изображений CAPTCHA с 
заданными параметрами. Данная библиотека поддерживает генерацию изображений с 
пользовательскими шрифтами и различными эффектами искажений, что исключает 
необходимость привлечения дополнительных инструментов.

Исходный код генератора синтетических CAPTCHA представлен в приложении~
\ref{code:gen-dataset}.

После создания изображений все они прошли этапы предобработки, направленные на 
улучшение качества данных и повышение эффективности обучения модели. 
Предобработка включала следующие этапы:

\begin{enumerate}
    \item преобразование изображений в градации серого для уменьшения количества 
    каналов и снижения вычислительной нагрузки;
    \item бинаризация изображений с целью получения контрастного представления 
    символов (белый текст на черном фоне);
    \item удаление шумов и фона с использованием морфологических операций, в 
    частности, дилатации.
\end{enumerate}

Исходный код обработчика изображений представлен в приложении~
\ref{code:preprocessing}.

Примеры сгенерированных и предобработанных CAPTCHA приведены на рисунке ниже:

\begin{figure}[H]
    \centering
    \begin{minipage}[h]{0.45\linewidth}
        \center{\includegraphics[width=1\linewidth]{imgs/textcaptcha/YKQ9.png}} 
        \\ а)
    \end{minipage}
    \begin{minipage}[h]{0.45\linewidth}
        \center{\includegraphics[width=1\linewidth]{imgs/textcaptcha/out.png}} 
        \\ б)
    \end{minipage}
    \caption{Изображения CAPTCHA: а) -- сгенерированное изображение, б) -- 
    результат обработки.}
    \label{fig:example-captcha}
\end{figure}

\vspace{-0.7cm}

\textbf{Подготовка датасета для CAPTCHA с изображениями}

Большинство предобученных моделей компьютерного зрения, таких как YOLOv8, обучены 
на датасете COCO~\cite{COCO}, содержащем изображения высокого качества с чёткими 
контурами и однозначной аннотацией объектов. Однако CAPTCHA с изображениями имеют 
принципиально иные характеристики: они могут включать в себя размытие, наложенные 
артефакты, искажения, шумы, повторяющиеся элементы и искусственно пониженное 
разрешение. Всё это снижает эффективность использования стандартных датасетов и 
моделей, не адаптированных под такие условия.

Для обеспечения высокой точности в задаче автоматического решения CAPTCHA 
необходимо подготовить собственный набор данных, приближённый к реальным условиям 
использования. Наиболее эффективным методом является автоматизированный парсинг 
изображений CAPTCHA, представленных на веб-сайтах, использующих визуальные 
CAPTCHA-решения, такие как Google reCAPTCHA v2.

Использование реальных CAPTCHA, собранных в автоматическом режиме, имеет ряд 
преимуществ по сравнению с синтетической генерацией данных:

\begin{enumerate}
    \item изображения содержат разнообразные сцены, освещение, углы обзора и 
    уровни шума, что положительно влияет на способность модели к обобщению;
    \item присутствует большое количество уникальных объектов на фоне, в том 
    числе в частично перекрытых и смазанных вариантах;
    \item отсутствует необходимость в ручной генерации изображений и создании 
    дополнительных искажений для повышения реалистичности;
    \item возможно извлекать текстовые инструкции к CAPTCHA, что позволяет 
    соотносить каждое изображение с требуемым классом.
\end{enumerate}

Для парсинга CAPTCHA был реализован автоматизированный сценарий взаимодействия с 
браузером с использованием библиотеки Selenium~\cite{Selenium}. Данный подход 
позволяет воспроизвести действия пользователя при работе с CAPTCHA, обходя при 
этом ручной ввод. Для обеспечения стабильной работы и масштабируемости процесса 
применялась браузерная автоматизация через WebDriver (в частности, ChromeDriver).

Функциональность парсера включает следующие ключевые этапы:

\begin{enumerate}
    \item поиск iframe-элемента, содержащего чекбокс <<Я не робот>>, и эмуляция 
    клика по нему для инициирования визуальной CAPTCHA;
    \item ожидание загрузки CAPTCHA и извлечение изображения с заданием (включая 
    его URL или пиксельный снимок);
    \item извлечение информации о структуре сетки (количество строк и столбцов), 
    на которую разбито изображение CAPTCHA;
    \item получение текста задания, содержащего имя объекта (например, <<выберите 
    все изображения с мотоциклами>>), для последующего использования в аннотации 
    данных.
\end{enumerate}

Типичная CAPTCHA представляет собой изображение, разделённое на сетку из 3×3 или 
4×4 ячеек, каждая из которых может содержать фрагмент сцены. При этом 
пользователю предлагается выбрать ячейки, в которых присутствует объект заданного 
класса. Процесс парсинга может быть представлена блок-схемой на рис.~
\ref{fig:captcha-flow}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{
        imgs/imagecaptcha/image_captcha_flow.png
    }
    \caption{Блок-схема процесса парсинга CAPTCHA.}
    \label{fig:captcha-flow}
\end{figure}
\vspace{-0.5cm}

Полученные изображения и метаданные (включая текст задания и параметры сетки) 
используются для формирования обучающего датасета, пригодного для дообучения 
модели YOLOv8 в задачах классификации и сегментации объектов.

После получения достаточного количества изображений для составления датасета 
необходимо провести их предварительную обработку и разметку. Это один из 
самыхважных этапов работы, поскольку от качества разметки напрямую зависит 
точность и эффективность последующей работы модели.

Для корректной работы модели YOLO требуется создать иерархическую структуру 
папок, в которой изображения и соответствующие метки будут разделены на 
тренировочную и валидационную выборки. Стандартная структура включает следующие 
директории:

\begin{enumerate}
    \item Директория train -- содержит тренировочную выборку:
    \begin{enumerate}
        \item images -- изображения;
        \item labels -- метки к изображениям.
    \end{enumerate}
    \item Директория val -- содержит валидационную выборку:
    \begin{enumerate}
        \item images -- изображения;
        \item labels -- метки к изображениям.
    \end{enumerate}
\end{enumerate}

Набор классов, пути к выборкам и параметры конфигурации задаются в YAML-файле, 
который передается при обучении модели. Содержимое такого файла для данной 
модели:

\begin{code}
    \captionof{listing}{
        \label{code:train-captcha}Параметры конфигурации для обучения модели
    }
    \vspace{-0.75cm}
    {\small
        \inputminted[mathescape,linenos,frame=lines,breaklines]{yaml}{code/imagecaptcha/train_captcha.yaml}
    }
\end{code}
\vspace{-0.4cm}

Для создания меток используется инструмент CVAT (Computer Vision Annotation Tool) 
-- многофункциональное веб-приложение с поддержкой аннотации объектов с помощью 
полигонов, прямоугольников и других форм. CVAT позволяет экспортировать разметку 
напрямую в формат, совместимый с YOLO~\cite{CVAT}.

Поскольку CAPTCHA-изображения часто содержат объекты с нечёткими контурами, 
наложением и визуальными искажениями, особенно важно использовать ручную точную 
разметку, а не ограничиваться автоматическими методами. Выделение объектов должно 
проводиться как можно точнее, с учётом геометрии контуров. На рисунке ниже 
представлен пример изображения с размеченными объектами:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{imgs/imagecaptcha/captcha-poligons.png}
    \caption{Пример разметки изображения с тестовой CAPTCHA.}
    \label{fig:mask-captcha}
\end{figure}
\vspace{-0.5cm}

Кроме того, разметка позволяет учесть сразу несколько объектов разных классов на 
одном изображении, что особенно характерно для CAPTCHA, где в одной сетке могут 
одновременно находиться, например, автомобили и автобусы. Такой подход 
положительно влияет на обобщающую способность модели.

В случае, если количество данных по отдельным классам окажется недостаточным, 
можно дополнительно использовать методы аугментации: вращение, масштабирование, 
искажение цвета и контраста. Однако при хорошо организованном парсинге и разметке 
зачастую удается обойтись без аугментации.
